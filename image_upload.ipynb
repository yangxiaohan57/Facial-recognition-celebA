{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset and Upload into S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we split the dataset into training, validation, and testing. Then we upload the three sub-datasets into three separate folders in AWS S3 bucket.\n",
    "\n",
    "We will only use a reduced number of images:\n",
    "- Training 20000 images\n",
    "- Validation 5000 images\n",
    "- Test 5000 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a folder structure in S3 bucket:\n",
    " - training_imgs\n",
    "   - images from 1 to 162770\n",
    " - validation_imgs:\n",
    "   - images from 162771 to 182637\n",
    " - testing_imgs:\n",
    "   - images from 182638 to 202599\n",
    " - user_imgs:\n",
    "   - images uploaded by user from web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2, boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import sagemaker\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constants\n",
    "'''\n",
    "\n",
    "TRAINING_SAMPLES = 1000 #10000\n",
    "VALIDATION_SAMPLES = 200 #2000\n",
    "TEST_SAMPLES = 200 #2000\n",
    "IMG_WIDTH = 178\n",
    "IMG_HEIGHT = 218\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Path constants\n",
    "'''\n",
    "interm = 'intermediate_files/'\n",
    "bucket = 'celeba-facial-recog'\n",
    "folder_s3 = {0: 'training_imgs/', 1:'validation_imgs/', 2: 'testing_imgs/'}\n",
    "local_filename = {0: 'train', 1:'validation', 2: 'test'}\n",
    "images_folder = 'img_align_celeba/img_align_celeba/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DF for partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in attribute dataset\n",
    "df_attr = pd.read_csv('list_attr_celeba.csv')\n",
    "df_attr.set_index('image_id', inplace=True)\n",
    "df_attr.replace(to_replace=-1, value=0, inplace=True) #replace -1 by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    162770\n",
       "2     19962\n",
       "1     19867\n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_partition = pd.read_csv('list_eval_partition.csv')\n",
    "df_partition['partition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the partition values into attribute data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000001.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000003.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000005.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            partition  Male\n",
       "image_id                   \n",
       "000001.jpg          0     0\n",
       "000002.jpg          0     0\n",
       "000003.jpg          0     1\n",
       "000004.jpg          0     0\n",
       "000005.jpg          0     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_partition.set_index('image_id', inplace=True)\n",
    "df_par_attr = df_partition.join(df_attr['Male'], how='inner')\n",
    "df_par_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n",
    "Split to three sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reshape_img(fname):\n",
    "    img = load_img(fname)\n",
    "    x = img_to_array(img)/255.\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    partition\n",
    "        0 -> train\n",
    "        1 -> validation\n",
    "        2 -> test\n",
    "    attr: 'Men'\n",
    "'''\n",
    "def generate_df(partition, attr, num_samples):\n",
    "    # half women half men\n",
    "    df_ = df_par_attr[(df_par_attr['partition'] == partition) \n",
    "                           & (df_par_attr[attr] == 0)].sample(int(num_samples/2))\n",
    "    df_ = pd.concat([df_,\n",
    "                      df_par_attr[(df_par_attr['partition'] == partition) \n",
    "                                  & (df_par_attr[attr] == 1)].sample(int(num_samples/2))])\n",
    "    \n",
    "    # for Train and Validation\n",
    "    if partition != 2:\n",
    "        x_ = np.array([load_reshape_img(images_folder + fname) for fname in df_.index])\n",
    "        x_ = x_.reshape(x_.shape[0], 218, 178, 3)\n",
    "        y_ = np_utils.to_categorical(df_[attr],2)\n",
    "    # for Test\n",
    "    else:\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        for index, target in df_.iterrows():\n",
    "            im = cv2.imread(images_folder + index)\n",
    "            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
    "            im = np.expand_dims(im, axis =0)\n",
    "            x_.append(im)\n",
    "            y_.append(target[attr])\n",
    "\n",
    "    return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload all images to S3\n",
    "def upload_imgs_data(partition, x_set, y_set):\n",
    "    x_filename = interm + 'x_' + local_filename[partition]\n",
    "    np.save(x_filename, x_set)\n",
    "    x_filename += '.npy'\n",
    "    print('Finished creating file:' + x_filename)\n",
    "    url = 's3://{}/{}'.format(bucket, folder_s3[partition])\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(x_filename, bucket, folder_s3[partition])\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "    print('Done writing {} to {}'.format(x_filename, url))\n",
    "    \n",
    "    y_filename = interm + 'y_' + local_filename[partition]\n",
    "    np.save(y_filename, y_set)\n",
    "    y_filename += '.npy'\n",
    "    print('Finished creating file:' + y_filename)\n",
    "    url = 's3://{}/{}'.format(bucket, folder_s3[partition])\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(y_filename, bucket, folder_s3[partition])\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "    print('Done writing {} to {}'.format(y_filename, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_train, y_train = generate_df(0, 'Male', TRAINING_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = generate_df(1, 'Male', VALIDATION_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating file:intermediate_files/x_train.npy\n",
      "Done writing intermediate_files/x_train.npy to s3://celeba-facial-recog/training_imgs/\n",
      "Finished creating file:intermediate_files/y_train.npy\n",
      "Done writing intermediate_files/y_train.npy to s3://celeba-facial-recog/training_imgs/\n"
     ]
    }
   ],
   "source": [
    "upload_imgs_data(0, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating file:intermediate_files/x_validation.npy\n",
      "Done writing intermediate_files/x_validation.npy to s3://celeba-facial-recog/validation_imgs/\n",
      "Finished creating file:intermediate_files/y_validation.npy\n",
      "Done writing intermediate_files/y_validation.npy to s3://celeba-facial-recog/validation_imgs/\n"
     ]
    }
   ],
   "source": [
    "upload_imgs_data(1, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation (modifying images):\n",
    "Data Augmentation allows to generate images with modifications to the original ones. The following code is just a illustration using example photo. We will do augmentation to the training dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen =  ImageDataGenerator(\n",
    "  #preprocessing_function=preprocess_input,\n",
    "  rotation_range=30,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_PIC = images_folder + '007324.jpg'\n",
    "\n",
    "# load one image and reshape\n",
    "img = load_img(EXAMPLE_PIC)\n",
    "x = img_to_array(img)/255.\n",
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 10 augmented images of the loaded iamge\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.suptitle('Data Augmentation', fontsize=28)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow( batch.reshape(218, 178, 3))\n",
    "    \n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Data Preparation - Data Augmentation with generators\n",
    "train_datagen =  ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input,\n",
    "  rotation_range=30,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation - Data Preparation - Data Augmentation with generators\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,)\n",
    "\n",
    "valid_datagen.fit(x_valid)\n",
    "\n",
    "validation_generator = valid_datagen.flow(x_valid, y_valid,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
